import torch
import os
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from common.util import get_latest_run_dir
from tqdm import tqdm
from verif.mae import mae, mae2d, plot_mae_timeseries, plot_mae2d
from verif.psd import psd, plot_psd
from verif.fss import fss, plot_fss
from verif.error_spread import error_spread, plot_error_spread
from verif.variance_ratio import variance_ratio, plot_variance_ratio
from verif.highk_power_ratio import highk_power_ratio, plot_highk_power_ratio
from verif.spectral_coherence import (
    spectral_coherence_bands,
    plot_spectral_coherence_bands,
)
from verif.change_metrics import (
    change_metrics,
    plot_change_prf_timeseries,
    plot_change_corr_stationarity_timeseries,
)
from verif.composite_score import (
    composite_score,
    plot_composite_bars,
    plot_component_contributions,
)


def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--run_name", type=str, required=True, nargs="+")
    parser.add_argument(
        "--score",
        type=str,
        required=False,
        nargs="+",
        choices=[
            "stamps",
            "mae",
            "mae2d",
            "psd",
            "fss",
            "variance_ratio",
            "highk_power_ratio",
            "spectral_coherence",
            "change_metrics",
            "error-spread",
        ],
        help="Score to produce",
    )
    parser.add_argument(
        "--save_path",
        type=str,
        default="runs/verification",
        help="Path to save the verification results and plots",
    )
    parser.add_argument(
        "--plot_only",
        action="store_true",
        help="If set, only plot the results without running the verification.",
    )

    args = parser.parse_args()

    os.makedirs(f"{args.save_path}/figures", exist_ok=True)
    os.makedirs(f"{args.save_path}/results", exist_ok=True)

    if args.score is None:
        args.score = ["mae"]

    if "stamps" in args.score and args.plot_only:
        raise ValueError("Cannot plot stamps without running verification.")

    return args


def read_data(run_name, ensemble_only):
    if "/" in run_name:
        run_dir = f"runs/{run_name}"
    else:
        run_dir = get_latest_run_dir(f"runs/{run_name}")

    assert run_dir, f"Run {run_name} not found in runs/"

    file_path = f"{run_dir}/test-output"

    predictions = torch.load(
        f"{file_path}/predictions.pt",
        map_location=torch.device("cpu"),
        weights_only=True,
    )
    truth = torch.load(
        f"{file_path}/truth.pt", map_location=torch.device("cpu"), weights_only=True
    )
    dates = torch.load(
        f"{file_path}/dates.pt", map_location=torch.device("cpu"), weights_only=True
    )

    if not ensemble_only and predictions.ndim == 6:
        # predictions are from pgu_ens, pick first member
        print("Using member 0/{}".format(predictions.shape[1]))
        predictions = predictions[:, 0, :, :, :]

    if truth.ndim == 6:
        # squeeze "member" dim from truth
        truth = truth[:, 0, :, :, :]

    assert (
        ensemble_only or predictions.ndim == 5
    ), "Predictions should be 5D tensor (batch, time, channel, height, width), got {}".format(
        predictions.shape
    )
    assert (
        truth.ndim == 5
    ), "Truth should be 5D tensor (batch, time, channel, height, width), got {}".format(
        truth.shape
    )
    return truth, predictions, dates


def union(all_truth, all_predictions, all_dates):
    # 1. Build union of all forecast sequences
    all_sets = [set(map(tuple, d.numpy())) for d in all_dates]
    union_keys = set().union(*all_sets)

    print(f"Total unique forecast sequences before union: {len(union_keys)}")

    # 2. Sort the union chronologically (by first lead time)
    sorted_union = sorted(union_keys, key=lambda row: row[0])

    # 3. For each run, filter and reorder according to sorted_union
    new_truth, new_predictions, new_dates = [], [], []

    for i, (truth, pred, dates) in enumerate(
        zip(all_truth, all_predictions, all_dates)
    ):
        date_dict = {tuple(row): idx for idx, row in enumerate(dates.numpy())}

        filtered_truth = []
        filtered_pred = []
        filtered_dates = []

        for key in sorted_union:
            if key in date_dict:
                idx = date_dict[key]
                filtered_truth.append(truth[idx])
                filtered_pred.append(pred[idx])
                filtered_dates.append(torch.tensor(key, dtype=torch.float64))

        if filtered_truth:
            new_truth.append(torch.stack(filtered_truth))
            new_predictions.append(torch.stack(filtered_pred))
            new_dates.append(torch.stack(filtered_dates))
        else:
            print(f"{run_name[i]}: No overlapping forecasts found!")

    print(f"Total forecast sequences after union: {new_predictions[0].shape[0]}")
    return new_truth, new_predictions, new_dates


def equalize_datasets(run_name, all_truth, all_predictions, all_dates):
    need_union = False

    for i in tqdm(range(1, len(all_dates)), desc="Equalizing"):
        if all_dates[i - 1].shape != all_dates[i].shape:
            print(
                "Different shape of dates for {} ({}) and {} ({})".format(
                    args.run_name[i - 1],
                    all_dates[i - 1].shape,
                    args.run_name[i],
                    all_dates[i].shape,
                )
            )

            a = all_dates[i]
            b = all_dates[i - 1]

            a = set(map(tuple, a.numpy()))
            b = set(map(tuple, b.numpy()))

            A_not_in_B = a - b
            B_not_in_A = b - a

            # Print rows

            if len(A_not_in_B):
                print("Rows in {} but not in {}:".format(run_name[i - 1], run_name[i]))
                for row in A_not_in_B:
                    d_s = [np.datetime64(int(x), "s") for x in row]
                    print(d_s)

            if len(B_not_in_A):
                print("Rows in {} but not in {}:".format(run_name[i], run_name[i - 1]))
                for row in B_not_in_A:
                    d_s = [np.datetime64(int(x), "s") for x in row]
                    print(d_s)

            need_union = True

    if need_union:
        # Filter predictions, truth and dates so that a union of both datasets
        # is picked

        return union(all_truth, all_predictions, all_dates)

    return all_truth, all_predictions, all_dates


def prepare_data(args, ensemble_only: bool = False):
    all_truth, all_predictions, all_dates = [], [], []

    for run_name in tqdm(args.run_name, desc="Reading data"):

        truth, predictions, dates = read_data(run_name, ensemble_only)

        if ensemble_only and predictions.ndim == 5:
            print(f"Skipping run {run_name}, not an ensemble")
            continue

        all_truth.append(truth)
        all_predictions.append(predictions)
        all_dates.append(dates)

    if len(all_dates) == 1:
        return all_truth, all_predictions, all_dates

    return equalize_datasets(args.run_name, all_truth, all_predictions, all_dates)


def plot_stamps(
    run_name: list[str],
    all_truth: list[torch.Tensor],
    all_predictions: list[torch.Tensor],
    all_dates: list[torch.Tensor],
    save_path: str,
):

    truth = all_truth[0][0]

    num_timesteps = truth.shape[0]
    num_models = len(all_predictions)
    nrows = 1 + num_models  # 1 row for truth + N rows for models
    ncols = num_timesteps

    # Dynamically adjust figsize - very rough estimate
    fig_width = ncols * 3
    fig_height = nrows * 3
    fig, axes = plt.subplots(
        nrows, ncols, figsize=(fig_width, fig_height), sharex=True, sharey=True
    )

    # If only one row/col, axes might not be a 2D array, handle this:
    if nrows == 1 and ncols == 1:
        axes = np.array([[axes]])
    elif nrows == 1:
        axes = np.array([axes])
    elif ncols == 1:
        axes = np.array([[ax] for ax in axes])  # Make it 2D Nrows x 1 col

    fig.suptitle(f"Ground Truth vs. Model Predictions", fontsize=24)
    cmap = "Blues"

    for r in range(nrows):
        if r == 0:
            img_data = truth
        else:
            img_data = all_predictions[r - 1][
                0
            ]  # select first forecast from each model

        for c in range(ncols):
            ax = axes[r, c]
            ax.set_xticks([])
            ax.set_yticks([])

            if c == 0:  # Set row labels on the first column
                if r == 0:
                    ax.set_ylabel("Ground Truth", fontsize=12, rotation=90, labelpad=10)
                else:
                    ax.set_ylabel(
                        f"{args.run_name[r-1]}", fontsize=12, rotation=90, labelpad=10
                    )

            im = ax.imshow(img_data[c, 0], cmap=cmap, vmin=0, vmax=1)

            if r == 0:  # Top row: Ground Truth
                ax.set_title(f"Leadtime {c}h", fontsize=16)

    # Adjust layout to prevent overlap
    plt.tight_layout(
        rect=[0, 0.03, 0.85, 0.95]
    )  # Adjust rect to make space for suptitle

    # Add colorbar
    cbar_ax = fig.add_axes([0.86, 0.039, 0.015, 0.85])  # [left, bottom, width, height]
    cbar = fig.colorbar(im, cax=cbar_ax)
    cbar.set_label("Cloud cover", rotation=90, labelpad=15, fontsize=16)

    filename = f"{save_path}/figures/stamps.png"
    plt.savefig(filename)
    print(f"Example timeseries plot saved to {filename}")
    plt.close(fig)


if __name__ == "__main__":
    args = get_args()

    if args.plot_only is False:
        all_truth, all_predictions, all_dates = prepare_data(args)

    pivot_df = None
    all_results = []
    for score in args.score:
        if score == "mae":
            if args.plot_only:
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results = mae(args.run_name, all_truth, all_predictions, args.save_path)
            plot_mae_timeseries(results, args.save_path)
            print(results)
            pivot_df = results.pivot(index="model", columns="timestep", values="mae")

        elif score == "mae2d":
            if args.plot_only:
                results = torch.load(
                    f"{args.save_path}/results/{score}.pt", weights_only=False
                )
            else:
                results = mae2d(all_truth, all_predictions, args.save_path)
            plot_mae2d(args.run_name, results, args.save_path)

        elif score == "psd":
            if args.plot_only:
                obs_psd = torch.load(
                    f"{args.save_path}/results/observed_psd.pt", weights_only=False
                )
                pred_psd = torch.load(
                    f"{args.save_path}/results/predicted_psd.pt", weights_only=False
                )
                pred_psd_r1 = torch.load(
                    f"{args.save_path}/results/predicted_psd_r1.pt", weights_only=False
                )
            else:
                obs_psd, pred_psd, pred_psd_r1 = psd(
                    all_truth, all_predictions, args.save_path
                )
            plot_psd(args.run_name, obs_psd, pred_psd, pred_psd_r1, args.save_path)
            results = (obs_psd, pred_psd, pred_psd_r1)


        elif score == "fss":
            if args.plot_only:
                results_t = torch.load(
                    f"{args.save_path}/results/{score}.pt", weights_only=False
                )
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results_t, results = fss(
                    args.run_name, all_truth, all_predictions, args.save_path
                )

            plot_fss(args.run_name, results_t, args.save_path)

        elif score == "error-spread":
            _all_truth, _all_predictions, _ = prepare_data(args, True)
            print(_all_truth[0].shape, _all_predictions[0].shape)
            results = error_spread(
                args.run_name, _all_truth, _all_predictions, args.save_path
            )
            print(results)
            plot_error_spread(results)

        elif score == "variance_ratio":
            if args.plot_only:
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results = variance_ratio(
                    args.run_name, all_truth, all_predictions, args.save_path
                )

            print(results)
            plot_variance_ratio(results, args.save_path)

        elif score == "highk_power_ratio":
            if args.plot_only:
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results = highk_power_ratio(
                    args.run_name, all_truth, all_predictions, args.save_path
                )

            print(results)
            plot_highk_power_ratio(results, args.save_path)

        elif score == "spectral_coherence":
            if args.plot_only:
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results = spectral_coherence_bands(
                    args.run_name, all_truth, all_predictions, args.save_path
                )

            print(results)
            plot_spectral_coherence_bands(results, args.save_path)

        elif score == "change_metrics":
            if args.plot_only:
                results = pd.read_csv(f"{args.save_path}/results/{score}.csv")
            else:
                results = change_metrics(
                    args.run_name, all_truth, all_predictions, args.save_path
                )

            print(results)
            plot_change_prf_timeseries(results, args.save_path)
            plot_change_corr_stationarity_timeseries(results, args.save_path)

        all_results.append(results)

    composite_score_metrics = [
        "mae",
        "fss",
        "variance_ratio",
        "highk_power_ratio",
        "spectral_coherence",
        "change_metrics",
    ]

    composite_score_values = {}
    for s in composite_score_metrics:
        if s not in args.score:
            break

        i = args.score.index(s)
        composite_score_values[s] = all_results[i]

    if len(composite_score_values.keys()) == 6:
        composite_result = composite_score(args.run_name, composite_score_values)
        plot_composite_bars(composite_result, save_path=args.save_path)
        plot_component_contributions(composite_result, save_path=args.save_path)

    else:
        print("Not producing composite score: some scores not calculated")

    if args.plot_only is False:
        plot_stamps(
            args.run_name, all_truth, all_predictions, all_dates, args.save_path
        )

    if pivot_df is not None:
        print(pivot_df)
